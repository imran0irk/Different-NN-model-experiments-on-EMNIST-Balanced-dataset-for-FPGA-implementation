{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a59457-6f70-43e1-85f0-2e7a69777458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bda884c-b5f3-4fe6-aeb7-b386ad185a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import custom_object_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82f23ee-f837-4222-9d46-7e9bffdb6aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qkeras import *\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense\n",
    "from qkeras import QConv2D\n",
    "from qkeras import quantized_bits, quantized_relu\n",
    "from qkeras.utils import load_qmodel\n",
    "from qkeras.utils import print_model_sparsity\n",
    "from qkeras.utils import model_save_quantized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6caf4969-7316-4c9e-9a96-892e5832d26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##FOr data from idx file_byte\n",
    "import struct\n",
    "def load_idx_file(file_path):\n",
    "    \"\"\"\n",
    "    Load data from an IDX file (either images or labels).\n",
    "    Returns:\n",
    "        numpy.ndarray: Loaded data as a NumPy array.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Read the magic number and dimensions\n",
    "        magic, = struct.unpack('>I', f.read(4))\n",
    "        if magic == 0x00000801:  # Labels\n",
    "            num_items, = struct.unpack('>I', f.read(4))\n",
    "            data = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_items)\n",
    "        elif magic == 0x00000803:  # Images\n",
    "            num_items, rows, cols = struct.unpack('>III', f.read(12))\n",
    "            data = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_items, rows, cols)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown magic number: {magic}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe19b33a-8ca9-4013-a808-d9763e7631d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 64\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 47\n",
    "VALIDATION_SPLIT = 0.1\n",
    "OPTIMIZER = Adam(learning_rate=0.001)\n",
    "#OPTIMIZER = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "W = 4  #QConv2d W_bit 8\n",
    "I = 0  # fractional bits\n",
    "Z = float(4)  #QActivation quantize_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06849bd2-2777-48f4-8abd-d66f10ab2307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "CALLBACKS = lr_schedule = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47f9e8dc-dd73-40b8-9a28-e62721464dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Flatten input (28x28 grayscale images for EMNIST)\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    \n",
    "    # First dense layer with quantized weights and activations\n",
    "    QDense(\n",
    "        128,  # Number of neurons\n",
    "        kernel_quantizer=quantized_bits(W, I, 1),  # W-bit weights with I fractional bits\n",
    "        bias_quantizer=quantized_bits(W, I, 1),    # W-bit biases\n",
    "        name=\"qdense_1\"\n",
    "    ),\n",
    "    QActivation(\"quantized_relu(6,2)\", name=\"qact_1\"),  # 6-bit activation with 2 fractional bits\n",
    "    \n",
    "    # Second dense layer\n",
    "    QDense(\n",
    "        64,  # Reduced neurons for lower complexity\n",
    "        kernel_quantizer=quantized_bits(W, I, 1),\n",
    "        bias_quantizer=quantized_bits(W, I, 1),\n",
    "        name=\"qdense_2\"\n",
    "    ),\n",
    "    QActivation(\"quantized_relu(6,2)\", name=\"qact_2\"),\n",
    "    \n",
    "    # Output layer\n",
    "    QDense(\n",
    "        47,  # EMNIST Balanced has 47 classes\n",
    "        kernel_quantizer=quantized_bits(W, I, 1),\n",
    "        bias_quantizer=quantized_bits(W, I, 1),\n",
    "        name=\"qoutput\"\n",
    "    ),\n",
    "    Activation(\"softmax\", name=\"Softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6b6c63-4145-40c0-85f6-26d668f64687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    x = x_in = Input(shape=input_shape, name=\"input_layer\")\n",
    "    a = QConv2D(\n",
    "        32, (2, 2), strides=(2, 2),\n",
    "        kernel_quantizer=quantized_bits(W, I, 1),\n",
    "        bias_quantizer=quantized_bits(W, I, 1),\n",
    "        name=\"conv2d_L1\")(x)\n",
    "    b = QActivation(\"quantized_relu(4, 0)\", name=\"activation_1\")(a)\n",
    "    c = QConv2D(\n",
    "        64, (3, 3), strides=(2, 2),\n",
    "        kernel_quantizer=quantized_bits(W, I, 1),\n",
    "        bias_quantizer=quantized_bits(W, I, 1),\n",
    "        name=\"conv2d_L2\")(b)\n",
    "    d = QActivation(\"quantized_relu(4, 0)\", name=\"activation_2\")(c)\n",
    "    e = QConv2D(\n",
    "        64, (2, 2), strides=(2, 2),\n",
    "        kernel_quantizer=quantized_bits(W, I, 1),\n",
    "        bias_quantizer=quantized_bits(W, I, 1),\n",
    "        name=\"conv2d_L3\")(d)\n",
    "    f = QActivation(\"quantized_relu(4, 0)\", name=\"activation_3\")(e)\n",
    "    g = Flatten()(f)\n",
    "    h = QDense(NB_CLASSES, kernel_quantizer=quantized_bits(W, I, 1),\n",
    "                   bias_quantizer=quantized_bits(W, I, 1),\n",
    "                   name=\"dense\")(g)\n",
    "    i = Activation(\"softmax\", name=\"Softmax\")(h)\n",
    "\n",
    "    model = Model(inputs=[x_in], outputs=[i])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ba848ce-7496-4ac9-94c0-e9961ed1fcef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "       # loss=\"sparse_categorical_crossentropy\",\n",
    "     #   loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer= OPTIMIZER,\n",
    "        metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Print the model summary.\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=NB_EPOCH,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        verbose=VERBOSE,\n",
    "        callbacks=[CALLBACKS],\n",
    "        validation_data=(x_test, y_test))\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "\n",
    "    print_model_sparsity(model)\n",
    "    \n",
    "    # Export and import the model. Check that accuracy persists.\n",
    "    _, keras_file = tempfile.mkstemp(suffix=\".keras\")  # Ensure the suffix is .keras\n",
    "    print(\"Saving model to:\", keras_file)\n",
    "    # Save the model in the new .keras format\n",
    "    #save_model(model, keras_file)\n",
    "    model.save(\"modelx.keras\", save_format=\"keras\")\n",
    "    print(\"Model saved to modelx.keras\")\n",
    "    print_qstats(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291e9227-6b84-4608-8477-ff9b62b8a7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (112800, 28, 28)\n",
      "Labels shape: (112800,)\n",
      "Images shape: (18800, 28, 28)\n",
      "Labels shape: (18800,)\n"
     ]
    }
   ],
   "source": [
    "image_file_train = \"/home/mindspore/work/emnist-balanced-train-images-idx3-ubyte\"\n",
    "label_file_train = \"/home/mindspore/work/emnist-balanced-train-labels-idx1-ubyte\"\n",
    "\n",
    "image_file_test = \"/home/mindspore/work/emnist-balanced-test-images-idx3-ubyte\"\n",
    "label_file_test = \"/home/mindspore/work/emnist-balanced-test-labels-idx1-ubyte\"\n",
    "\n",
    "x_train = load_idx_file(image_file_train)  # Load train images\n",
    "y_train = load_idx_file(label_file_train)  # Load train labels\n",
    "\n",
    "x_test = load_idx_file(image_file_test)  # Load test images\n",
    "y_test = load_idx_file(label_file_test)  # Load test labels\n",
    "\n",
    "print(\"Images shape:\", x_train.shape)\n",
    "print(\"Labels shape:\", y_train.shape)\n",
    "print(\"Images shape:\", x_test.shape)\n",
    "print(\"Labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2954d003-1270-4d97-91ff-3e2436aa8c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (112800, 28, 28)\n",
      "112800 train samples\n",
      "18800 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices //one-hot key 0-9 class matrice lable 0/1\n",
    "y_train = to_categorical(y_train, NB_CLASSES)\n",
    "y_test = to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c2a01-6c3b-4f3a-a121-ad1015ccc49d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train model and save data\n",
    "\n",
    "train_and_save(model, x_train, y_train, x_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a98bb-e5d2-4921-bab8-910006259426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Reloading model\")\n",
    "    \n",
    "with custom_object_scope({'TFOpLambda': Lambda}):\n",
    "        loaded_model = load_qmodel('modelx.keras')\n",
    "\n",
    "loaded_model.summary()  \n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0e86b-e902-425e-9e65-912eb68112c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
